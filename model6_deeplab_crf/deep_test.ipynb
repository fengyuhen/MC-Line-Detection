{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "#from deeplabv3 import relu6, BilinearUpsampling\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.utils import conv_utils, multi_gpu_model\n",
    "from keras.utils.data_utils import get_file\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_paths(dataset_path, list_path):\n",
    "    imagepaths = []\n",
    "    labelpaths = []\n",
    "    for path in tqdm(open(list_path)):\n",
    "        md5 = path.split('.')[0]\n",
    "        imagepaths.append(dataset_path + \"images/%s.jpg\"%md5)\n",
    "        labelpaths.append(dataset_path + \"spline_labels/%s.json\"%md5)\n",
    "    return imagepaths, labelpaths\n",
    "\n",
    "# detect points for one image\n",
    "def detect_points(img, model, shape):\n",
    "    img = cv2.resize(img, (shape,shape))\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    points_logist = model.predict(img)\n",
    "    points = np.argmax(points_logist, axis=-1)\n",
    "    return points[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mc16/.local/lib/python2.7/site-packages/keras/models.py:282: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n",
      "2015it [00:00, 298166.26it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from deeplabv3 import relu6, BilinearUpsampling\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "def config_keras_backend(gpu_memory_fraction):\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = gpu_memory_fraction\n",
    "    sess = tf.Session(config=config)\n",
    "    K.set_session(sess)\n",
    "\n",
    "GPU_MEMORY_FRACTION = 0.1\n",
    "config_keras_backend(GPU_MEMORY_FRACTION)\n",
    "model = load_model('deeplab_0614.h5', custom_objects={'relu6':relu6, 'BilinearUpsampling':BilinearUpsampling})\n",
    "# use val set to show the result example\n",
    "val_set_path = '/data/mc_data/MLDC/data/val/'\n",
    "val_list_path = '/data/mc_data/MLDC/data/val/list.txt'\n",
    "val_image_paths, val_label_paths = read_paths(val_set_path, val_list_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/home/mc16/pre_data/val_label_224.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-40aca5d2b28e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mDATA_SHAPE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#train_labels = np.load('/home/mc16/pre_data/train_label_%s.npy'%DATA_SHAPE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/mc16/pre_data/val_label_%s.npy'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mDATA_SHAPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#train_images = np.load('/home/mc16/pre_data/train_image_%s.npy'%DATA_SHAPE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mval_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/mc16/pre_data/val_image_%s.npy'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mDATA_SHAPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mc16/.local/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home/mc16/pre_data/val_label_224.npy'"
     ]
    }
   ],
   "source": [
    "# show the detected points on a valid image\n",
    "DATA_SHAPE = 224\n",
    "#train_labels = np.load('/home/mc16/pre_data/train_label_%s.npy'%DATA_SHAPE)\n",
    "val_labels = np.load('/home/mc16/pre_data/val_label_%s.npy'%DATA_SHAPE)\n",
    "#train_images = np.load('/home/mc16/pre_data/train_image_%s.npy'%DATA_SHAPE)\n",
    "val_images = np.load('/home/mc16/pre_data/val_image_%s.npy'%DATA_SHAPE)\n",
    "\n",
    "test_index = random.randint(0, len(val_labels))\n",
    "test_label = val_labels[test_index,:,:,1]\n",
    "test_img = plt.imread(val_image_paths[test_index])\n",
    "test_img = cv2.resize(test_img,(DATA_SHAPE,DATA_SHAPE))\n",
    "test_points = detect_points(test_img, model, DATA_SHAPE)\n",
    "fig, axs = plt.subplots(1, 3, figsize=(30,30)) \n",
    "axs[0].imshow(test_img)\n",
    "axs[1].imshow(test_label,cmap='gray')\n",
    "axs[2].imshow(test_points,cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda2]",
   "language": "python",
   "name": "conda-env-anaconda2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
