{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** loading labels **********\n",
      "********** loading images **********\n",
      "********** building model **********\n",
      "********** training... **********\n",
      "Train on 20000 samples, validate on 2015 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 103s 5ms/step - loss: 0.9514 - acc: 0.5521 - val_loss: 0.9041 - val_acc: 0.6629\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 86s 4ms/step - loss: 0.8361 - acc: 0.6499 - val_loss: 0.7870 - val_acc: 0.8129\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 88s 4ms/step - loss: 0.7781 - acc: 0.7104 - val_loss: 0.7613 - val_acc: 0.8077\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 89s 4ms/step - loss: 0.7297 - acc: 0.7553 - val_loss: 0.7185 - val_acc: 0.8354\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 88s 4ms/step - loss: 0.6893 - acc: 0.7872 - val_loss: 0.7057 - val_acc: 0.7536\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 87s 4ms/step - loss: 0.6530 - acc: 0.8124 - val_loss: 0.6473 - val_acc: 0.8350\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 87s 4ms/step - loss: 0.6208 - acc: 0.8321 - val_loss: 0.6417 - val_acc: 0.8181\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 86s 4ms/step - loss: 0.5927 - acc: 0.8473 - val_loss: 0.6102 - val_acc: 0.8443\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 88s 4ms/step - loss: 0.5693 - acc: 0.8591 - val_loss: 0.5828 - val_acc: 0.8917\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 88s 4ms/step - loss: 0.5478 - acc: 0.8688 - val_loss: 0.5876 - val_acc: 0.8971\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 88s 4ms/step - loss: 0.5297 - acc: 0.8765 - val_loss: 0.5715 - val_acc: 0.8593\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 89s 4ms/step - loss: 0.5146 - acc: 0.8825 - val_loss: 0.5416 - val_acc: 0.9062\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 87s 4ms/step - loss: 0.5010 - acc: 0.8875 - val_loss: 0.5803 - val_acc: 0.8326\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 88s 4ms/step - loss: 0.4892 - acc: 0.8914 - val_loss: 0.5486 - val_acc: 0.8802\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 88s 4ms/step - loss: 0.4766 - acc: 0.8952 - val_loss: 0.5305 - val_acc: 0.9154\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 89s 4ms/step - loss: 0.4682 - acc: 0.8979 - val_loss: 0.5288 - val_acc: 0.9036\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 89s 4ms/step - loss: 0.4583 - acc: 0.9004 - val_loss: 0.5396 - val_acc: 0.8832\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 88s 4ms/step - loss: 0.4524 - acc: 0.9024 - val_loss: 0.5193 - val_acc: 0.9063\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 87s 4ms/step - loss: 0.4461 - acc: 0.9039 - val_loss: 0.5162 - val_acc: 0.9074\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 89s 4ms/step - loss: 0.4388 - acc: 0.9059 - val_loss: 0.5362 - val_acc: 0.9259\n",
      "********** saveing mdoel **********\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers, Input, Model, Sequential, optimizers\n",
    "from keras.layers import Reshape, Merge, Lambda\n",
    "from keras.layers import Layer, Dense, Dropout, Activation, Flatten, Reshape, Permute\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing import image\n",
    "import keras.backend as K\n",
    "from keras.engine import Layer\n",
    "from keras.utils import multi_gpu_model, np_utils\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "#checkpoint = ModelCheckpoint('seg.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='max')\n",
    "#earlystop = EarlyStopping(monitor='val_loss', patience=5, mode='max')\n",
    "#callback_list = [earlystop]\n",
    "\n",
    "GPU_MEMORY_FRACTION = 1.0\n",
    "DATA_SHAPE = 224\n",
    "# hyparameters to tune\n",
    "BATCH_SIZE = 240\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 20\n",
    "CLASS_WEIGHT = np.array([1,20])\n",
    "\n",
    "def segnet(shape=224):\n",
    "    kernel = 3\n",
    "    filter_size = 64\n",
    "    pad = 1\n",
    "    pool_size = 2\n",
    "    model = Sequential()\n",
    "    model.add(Layer(input_shape=(shape , shape ,3)))\n",
    "    # encoder\n",
    "    model.add(ZeroPadding2D(padding=(pad,pad)))\n",
    "    model.add(Conv2D(filter_size, (kernel, kernel), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "    model.add(ZeroPadding2D(padding=(pad,pad)))\n",
    "    model.add(Conv2D(128, (kernel, kernel), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "    model.add(ZeroPadding2D(padding=(pad,pad)))\n",
    "    model.add(Conv2D(256, (kernel, kernel), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "    model.add(ZeroPadding2D(padding=(pad,pad)))\n",
    "    model.add(Conv2D(512, (kernel, kernel), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    # decoder\n",
    "    model.add( ZeroPadding2D(padding=(pad,pad)))\n",
    "    model.add( Conv2D(512, (kernel, kernel), padding='valid'))\n",
    "    model.add( BatchNormalization())\n",
    "    model.add( UpSampling2D(size=(pool_size,pool_size)))\n",
    "    model.add( ZeroPadding2D(padding=(pad,pad)))\n",
    "    model.add( Conv2D(256, (kernel, kernel), padding='valid'))\n",
    "    model.add( BatchNormalization())\n",
    "    model.add( UpSampling2D(size=(pool_size,pool_size)))\n",
    "    model.add( ZeroPadding2D(padding=(pad,pad)))\n",
    "    model.add( Conv2D(128, (kernel, kernel), padding='valid'))\n",
    "    model.add( BatchNormalization())\n",
    "    model.add( UpSampling2D(size=(pool_size,pool_size)))\n",
    "    model.add( ZeroPadding2D(padding=(pad,pad)))\n",
    "    model.add( Conv2D(filter_size, (kernel, kernel), padding='valid'))\n",
    "    model.add( BatchNormalization())\n",
    "    model.add(Conv2D(2, (1, 1), padding='valid',))\n",
    "    model.outputHeight = model.output_shape[-2]\n",
    "    model.outputWidth = model.output_shape[-3] \n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "def config_keras_backend(fraction):\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = fraction \n",
    "    sess = tf.Session(config=config)\n",
    "    K.set_session(sess)\n",
    "    \n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    weights = K.variable(weights)\n",
    "    def loss(y_true, y_pred):\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    return loss\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    print(\"********** loading labels **********\")\n",
    "    train_labels = np.load('/home/mc16/pre_data/train_label_%s.npy'%DATA_SHAPE)\n",
    "    val_labels = np.load('/home/mc16/pre_data/val_label_%s.npy'%DATA_SHAPE)\n",
    "    \n",
    "    print(\"********** loading images **********\")\n",
    "    train_images = np.load('/home/mc16/pre_data/train_image_%s.npy'%DATA_SHAPE)\n",
    "    val_images = np.load('/home/mc16/pre_data/val_image_%s.npy'%DATA_SHAPE)\n",
    "    \n",
    "    print(\"********** building model **********\")\n",
    "    config_keras_backend(GPU_MEMORY_FRACTION)\n",
    "    seg = segnet(DATA_SHAPE)\n",
    "    parallel_seg = multi_gpu_model(seg,gpus=8)\n",
    "    \n",
    "    print('********** training... **********')\n",
    "    loss = weighted_categorical_crossentropy(CLASS_WEIGHT)\n",
    "    adam = Adam(lr=LEARNING_RATE)\n",
    "    parallel_seg.compile(loss=loss, optimizer=adam, metrics=['accuracy'])\n",
    "    parallel_seg.fit(x = train_images, \n",
    "                         y = train_labels,\n",
    "                         batch_size = BATCH_SIZE,\n",
    "                         epochs = EPOCHS,\n",
    "                         verbose = 1,\n",
    "                         validation_data = (val_images, val_labels),\n",
    "                         shuffle = True)\n",
    "    print('********** saveing mdoel **********')\n",
    "    seg.save('seg_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed to create session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-59635718e379>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mconfig_keras_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGPU_MEMORY_FRACTION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'seg0608.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-59635718e379>\u001b[0m in \u001b[0;36mconfig_keras_backend\u001b[0;34m(fraction)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_growth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mper_process_gpu_memory_fraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mc16/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m   1558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m     \"\"\"\n\u001b[0;32m-> 1560\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1561\u001b[0m     \u001b[0;31m# NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mc16/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed to create session."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "\n",
    "GPU_MEMORY_FRACTION = 0.05\n",
    "def config_keras_backend(fraction):\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = fraction \n",
    "    sess = tf.Session(config=config)\n",
    "    K.set_session(sess)\n",
    "    \n",
    "config_keras_backend(GPU_MEMORY_FRACTION)\n",
    "model = load_model('seg0608.h5')\n",
    "\n",
    "import pydensecrf.densecrf as dcrf\n",
    "from pydensecrf.utils import compute_unary, create_pairwise_bilateral, create_pairwise_gaussian, unary_from_softmax\n",
    "\n",
    "def crf_image(img, model):\n",
    "    img = cv2.resize(img, (DATA_SHAPE, DATA_SHAPE))\n",
    "    score = model.predict(np.expand_dims(img,axis=0))\n",
    "    softmax = score[0].transpose((2, 0, 1)) # [channel,shap,shape]\n",
    "    # The input should be the negative of the logarithm of probability values\n",
    "    # Look up the definition of the softmax_to_unary for more information\n",
    "    unary = unary_from_softmax(softmax)\n",
    "    # The inputs should be C-continious -- we are using Cython wrapper\n",
    "    unary = np.ascontiguousarray(unary)#(2,n)\n",
    "    crf = dcrf.DenseCRF(img.shape[0] * img.shape[1], 2)\n",
    "    crf.setUnaryEnergy(unary)\n",
    "\n",
    "    # This potential penalizes small pieces of segmentation that are\n",
    "    # spatially isolated -- enforces more spatially consistent segmentations\n",
    "    feats = create_pairwise_gaussian(sdims=(3,5), shape=img.shape[:2])\n",
    "    crf.addPairwiseEnergy(feats, compat=3, kernel=dcrf.DIAG_KERNEL, normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "\n",
    "    # This creates the color-dependent features --\n",
    "    # because the segmentation that we get from CNN are too coarse\n",
    "    # and we can use local color features to refine them\n",
    "    feats = create_pairwise_bilateral(sdims=(50,50), schan=(20, 20, 20), img=img, chdim=2)\n",
    "    crf.addPairwiseEnergy(feats, compat=10, kernel=dcrf.DIAG_KERNEL, normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "\n",
    "    # mean field iteration\n",
    "    Q = crf.inference(1)\n",
    "    \n",
    "    res = np.argmax(Q, axis=0).reshape((img.shape[0], img.shape[1]))\n",
    "    return res    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2015it [00:00, 246997.77it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def read_paths(dataset_path, list_path):\n",
    "    imagepaths = []\n",
    "    labelpaths = []\n",
    "    for path in tqdm(open(list_path)):\n",
    "        md5 = path.split('.')[0]\n",
    "        imagepaths.append(dataset_path + \"images/%s.jpg\"%md5)\n",
    "        labelpaths.append(dataset_path + \"spline_labels/%s.json\"%md5)\n",
    "    return imagepaths, labelpaths\n",
    "\n",
    "# detect points for one image\n",
    "def detect_points(img, model, shape):\n",
    "    img = cv2.resize(img, (shape,shape))\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    points_logist = model.predict(img)\n",
    "    points = np.argmax(points_logist, axis=-1)\n",
    "    return points[0]\n",
    "\n",
    "val_set_path = '/data/mc_data/MLDC/data/val/'\n",
    "val_list_path = '/data/mc_data/MLDC/data/val/list.txt'\n",
    "val_image_paths, val_label_paths = read_paths(val_set_path, val_list_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_SHAPE = 224\n",
    "train_labels = np.load('/home/mc16/pre_data/train_label_%s.npy'%DATA_SHAPE)\n",
    "val_labels = np.load('/home/mc16/pre_data/val_label_%s.npy'%DATA_SHAPE)\n",
    "train_images = np.load('/home/mc16/pre_data/train_image_%s.npy'%DATA_SHAPE)\n",
    "val_images = np.load('/home/mc16/pre_data/val_image_%s.npy'%DATA_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a995c00f7c13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# test_index = 100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_image_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_SHAPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDATA_SHAPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "test_index = random.randint(0, len(val_labels))\n",
    "# test_index = 100\n",
    "test_label = val_labels[test_index,:,:,1]\n",
    "test_img = plt.imread(val_image_paths[test_index])\n",
    "test_img = cv2.resize(test_img,(DATA_SHAPE,DATA_SHAPE))\n",
    "test_mask = crf_image(test_img, model)\n",
    "test_points = detect_points(test_img, model, DATA_SHAPE)\n",
    "fig, axs = plt.subplots(1, 4, figsize=(30,30)) \n",
    "axs[0].imshow(test_img)\n",
    "axs[1].imshow(test_label,cmap='gray')\n",
    "axs[2].imshow(test_points,cmap='gray')\n",
    "axs[3].imshow(test_mask,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'crf_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c10bdb81845d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrf_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA_SHAPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'crf_image' is not defined"
     ]
    }
   ],
   "source": [
    "test_mask = crf_image(test_img, model)\n",
    "test_points = detect_points(test_img, model, DATA_SHAPE)\n",
    "fig, axs = plt.subplots(1, 4, figsize=(30,30)) \n",
    "axs[0].imshow(test_img)\n",
    "axs[1].imshow(test_label,cmap='gray')\n",
    "axs[2].imshow(test_points,cmap='gray')\n",
    "axs[3].imshow(test_mask,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:29: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "DATA_SHAPE = 224\n",
    "\n",
    "# val_labels = np.load('/home/mc16/pre_data/val_label_%s.npy'%DATA_SHAPE)\n",
    "# val_detect_points = np.load('/home/mc16/result/val_masks_06-11-18:34:58.npy')\n",
    "# test_detect_points = np.load('/home/mc16/result/test_masks_06-11-18:34:33.npy')\n",
    "\n",
    "# points in one image\n",
    "def matrix_to_point(detect_points):\n",
    "    points_list = []\n",
    "    for x in range(detect_points.shape[0]):\n",
    "        for y in range(detect_points.shape[1]):\n",
    "            if(detect_points[x][y] == 1):\n",
    "                points_list.append([x, y])\n",
    "    return np.array(points_list)\n",
    "val_point_data = matrix_to_point(test_points)\n",
    "\n",
    "# cluster in one image\n",
    "def get_cluster_points(points, EPS = 1.5, MIN_SAMPLES = 3):\n",
    "    if points == []: \n",
    "        cluster_points = []\n",
    "    else:\n",
    "        arpoints = np.array(points)\n",
    "        cluster_label = DBSCAN(eps=EPS, min_samples=MIN_SAMPLES).fit_predict(arpoints)\n",
    "        max_label = np.max(cluster_label)\n",
    "        cluster_points = []\n",
    "        for label in range(-1, max_label+1):\n",
    "            label_index = np.where(cluster_label == label)\n",
    "            cluster_points.append(arpoints[label_index])\n",
    "    return cluster_points\n",
    "val_cluster_list = get_cluster_points(val_point_data, EPS = 1.5, MIN_SAMPLES = 3)\n",
    "\n",
    "def cluster_to_img(cluster_points, shape):\n",
    "    pic = np.zeros((shape, shape), np.uint8)\n",
    "    num_label = cluster_points.shape[0]\n",
    "    for i in range(num_label):\n",
    "        for point in cluster_points[i]:\n",
    "            pic[point[0], point[1]] = i * int(255 / num_label)\n",
    "    return pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169.0\n",
      "0.87266463\n",
      "171.0\n",
      "0.8901179\n",
      "173.0\n",
      "0.9075712\n",
      "167.0\n",
      "0.8552113\n",
      "175.0\n",
      "0.9250245\n",
      "165.0\n",
      "0.83775806\n",
      "163.0\n",
      "0.82030475\n",
      "177.0\n",
      "0.94247776\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABrYAAAMbCAYAAAAIL6XqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<Figure size 2160x2160 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "val_h = np.load('/home/mc16/result/val_fit_06-13-02:27:32.npy')\n",
    "val_masks = np.load('/home/mc16/result/val_masks_06-12-00:43:14.npy')\n",
    "\n",
    "test_index = 100\n",
    "\n",
    "test_mask = val_masks[test_index]\n",
    "\n",
    "h_lines = val_h[test_index][:]\n",
    "#edges = cv2.Canny(h_lines, 50,200)\n",
    "lines = cv2.HoughLines(test_mask, 2, np.pi/180, 100)\n",
    "#print(lines[0])\n",
    "\n",
    "\n",
    "#def draw_hough(lines):\n",
    "pic = np.zeros((224,224), dtype=np.uint8)\n",
    "    #if(len(lines) == 0):\n",
    "    #    return pic\n",
    "    #for rho,theta in lines[0]:\n",
    "for line in lines[0]:\n",
    "    rho = line[0]\n",
    "    theta = line[1]\n",
    "    print(rho)\n",
    "    print(theta)\n",
    "    if theta<(np.pi/4.) or theta>(3.*np.pi/4.0):\n",
    "        pt1=(int(rho/np.cos(theta)),0)\n",
    "    a=np.cos(theta)\n",
    "    b=np.sin(theta)\n",
    "    x0=a*rho\n",
    "    y0=b*rho\n",
    "    x1=int(x0+1000*(-b))\n",
    "    y1=int(y0+1000*(a))\n",
    "    x2=int(x0-1000*(-b))\n",
    "    y2=int(y0-1000*(a))\n",
    "    cv2.line(pic,(x1,y1),(x2,y2),255,2)\n",
    "    #return pic\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(30,30)) \n",
    "axs[0].imshow(test_mask,cmap='gray')\n",
    "hough_img = draw_hough(lines)\n",
    "axs[1].imshow(hough_img,cmap='gray')\n",
    "# axs[2].imshow(test_points,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22015, 224, 224, 3)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_SHAPE = 224\n",
    "train_images = np.load('/home/mc16/pre_data/train_image_%s.npy'%DATA_SHAPE)\n",
    "val_images = np.load('/home/mc16/pre_data/val_image_%s.npy'%DATA_SHAPE)\n",
    "train_images = np.concatenate((train_images,val_images),axis=0)\n",
    "train_images.shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda2]",
   "language": "python",
   "name": "conda-env-anaconda2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
