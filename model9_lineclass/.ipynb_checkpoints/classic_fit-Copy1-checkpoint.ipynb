{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important;}<style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:100% !important;}<style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit three kinds of line\n",
    "- 1：一条直线（一次函数拟合并延长）\n",
    "- 2：一条曲线（按X轴取像素中心拟合）\n",
    "- 3：Y型线&顶部粘住的两条线（分两条按X轴取像素中心拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/mc16/.local/lib/python2.7/site-packages/keras/models.py:282: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import cv2\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import load_model, Sequential, model_from_json\n",
    "import random\n",
    "from sklearn.cluster import DBSCAN\n",
    "import os\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import *\n",
    "from keras.layers.pooling import MaxPool2D, AveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "TIMEFORMAT = \"%m-%d-%H:%M:%S\"\n",
    "GPU_MEMORY_FRACTION = 1.0\n",
    "DATA_SHAPE = 224\n",
    "\n",
    "def config_keras_backend(fraction):\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = fraction\n",
    "    sess = tf.Session(config=config)\n",
    "    K.set_session(sess)\n",
    "\n",
    "config_keras_backend(GPU_MEMORY_FRACTION)\n",
    "model = load_model('/home/mc16/model3/unet0615.h5')\n",
    "val_images = np.load('/home/mc16/pre_data/val_image.npy')\n",
    "val_labels = np.load('/home/mc16/pre_data/val_label_w3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_points(img, model, shape):\n",
    "    img = cv2.resize(img, (shape,shape))\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    points_logist = model.predict(img)\n",
    "    points = np.argmax(points_logist, axis=-1)\n",
    "    return points[0]\n",
    "\n",
    "def cut_top(mask, thresh, frac=0.04):\n",
    "    cut_mask = np.array(mask)\n",
    "    sum_mask = np.sum(mask, axis=1)\n",
    "    top_index = 0\n",
    "    for i in range(len(sum_mask)):\n",
    "        if (sum_mask[i] > thresh):\n",
    "            top_index = i\n",
    "            break\n",
    "    cut_index = top_index + int((224 - top_index) * frac)\n",
    "    cut_mask[:cut_index,:] = 0\n",
    "    return cut_mask, top_index\n",
    "\n",
    "def matrix_to_point(matrix):\n",
    "    points = []\n",
    "    for x in range(matrix.shape[0]):\n",
    "        for y in range(matrix.shape[1]):\n",
    "            if(matrix[x][y] == 1):\n",
    "                points.append([x, y])\n",
    "    return np.array(points, dtype=np.uint8)\n",
    "\n",
    "def get_clusters(points, EPS = 1.5, MIN_SAMPLES = 3, minN=20, RANGE = 20):\n",
    "    if len(points) == 0: \n",
    "        cluster_list = []\n",
    "    else:\n",
    "        arpoints = np.array(points, dtype=np.uint8)\n",
    "        cluster_label = DBSCAN(eps=EPS, min_samples=MIN_SAMPLES).fit_predict(arpoints)\n",
    "        max_label = np.max(cluster_label)\n",
    "        min_label = np.min(cluster_label)\n",
    "        cluster_list = []\n",
    "        for label in range(min_label, max_label+1):\n",
    "            label_index = np.where(cluster_label == label)\n",
    "            if(len(label_index[0]) > minN):\n",
    "                temp_cluster = arpoints[label_index]                \n",
    "                x = temp_cluster[:, 0]\n",
    "                y = temp_cluster[:, 1]\n",
    "                x_range = x.max() - x.min()\n",
    "                y_range = y.max() - y.min()\n",
    "                if max(x_range, y_range) > RANGE:\n",
    "                    cluster_list.append(temp_cluster)\n",
    "    return np.array(cluster_list)\n",
    "\n",
    "def cluster_to_img(cluster_points, shape):\n",
    "    pic = np.zeros((shape, shape), np.uint8)\n",
    "    num_label = cluster_points.shape[0]\n",
    "    for i in range(num_label):\n",
    "        for point in cluster_points[i]:\n",
    "            pic[point[0], point[1]] = 50 + i * int((255 - 50) / num_label) \n",
    "    return pic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 straight line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_line_info(points):\n",
    "    ## 得到符合条件的line, line_info\n",
    "    ## 返回points, line_info_right, line_info_polar\n",
    "    line_info_right = []\n",
    "    line_info_polar = []\n",
    "    for line_num in range(points.shape[0]):\n",
    "        x = points[line_num][:, 0]\n",
    "        y = points[line_num][:, 1] \n",
    "        z = np.polyfit(x, y, 1)\n",
    "        p = np.poly1d(z)\n",
    "        line_info_right.append(z)\n",
    "        z_j = z.copy()\n",
    "        z_j[0] = (math.atan(z_j[0]) * 180 / math.pi) - 90\n",
    "        z_j[1] = abs(z_j[1] * math.sin(z_j[0]))\n",
    "        line_info_polar.append(z_j)\n",
    "    return points, line_info_right, line_info_polar\n",
    "\n",
    "## 根据传入的每条线的极坐标参数，角度阈值，距离阈值，将符合条件的簇删掉（todo 合并）\n",
    "def get_flg_arr(line_info_polar, ANGEL, DIS):\n",
    "    flg = [0 for i in range(len(line_info_polar))]\n",
    "    flg_id = 1\n",
    "    for i in range(len(line_info_polar)):\n",
    "        if flg[i] == 0:\n",
    "            flg[i] = flg_id\n",
    "            flg_id += 1\n",
    "        else:\n",
    "            continue\n",
    "        for j in range(i + 1, len(line_info_polar)):\n",
    "            if flg[j] != 0:\n",
    "                continue\n",
    "            if abs(line_info_polar[i][0] - line_info_polar[j][0]) < ANGEL and abs(line_info_polar[i][1] - line_info_polar[j][1]) < DIS:\n",
    "                flg[j] = flg[i]\n",
    "    return flg\n",
    "\n",
    "# input struct line -> point\n",
    "def fit_straight_lines(straight_clusters, x_min, ANGEL=20, DIS=20):\n",
    "    line_list = []\n",
    "    if(len(straight_clusters)==0):\n",
    "        return line_list\n",
    "        \n",
    "    x_min_mean = x_min\n",
    "    straight_clusters, line_info_right, line_info_polar = get_line_info(straight_clusters)\n",
    "    if(len(straight_clusters)==0):\n",
    "        return line_list\n",
    "    flg = get_flg_arr(line_info_polar, ANGEL, DIS)\n",
    "    temp_x = range(x_min_mean, 223)\n",
    "    flg_id = 1; zs = []\n",
    "    while flg_id <= np.array(flg).max():\n",
    "        z = [0, 0]\n",
    "        x_max_range = 0\n",
    "        max_index = 0\n",
    "        for i in range(flg.__len__()):\n",
    "            if flg[i] == flg_id:\n",
    "                cur_x_range = straight_clusters[i][:,0].max() - straight_clusters[i][:,0].min()\n",
    "                if cur_x_range > x_max_range:\n",
    "                    x_max_range = cur_x_range\n",
    "                    max_index = i\n",
    "                \n",
    "        z[0] = line_info_right[max_index][0]\n",
    "        z[1] = line_info_right[max_index][1]\n",
    "        zs.append(z)\n",
    "        flg_id += 1\n",
    "        \n",
    "    for line_num in range(zs.__len__()):\n",
    "        temp_x_y = []\n",
    "        line_p = np.poly1d(zs[line_num])\n",
    "        temp_y = line_p(temp_x)\n",
    "        j = 0\n",
    "        for i in range(temp_x.__len__()):\n",
    "            if temp_y[i] < 0 or temp_y[i] > 223:\n",
    "                continue\n",
    "            temp_x_y.append([temp_x[i], int(temp_y[i])])\n",
    "        line_list.append(temp_x_y)\n",
    "        \n",
    "    return line_list\n",
    "\n",
    "def lines_to_img(lines, shape):\n",
    "    pic = np.zeros((shape, shape), np.uint8)\n",
    "    for line in lines:\n",
    "        for point in line:\n",
    "            pic[point[0], point[1]] = 255\n",
    "    return pic\n",
    "\n",
    "def cluster_to_img(cluster_points, shape):\n",
    "    pic = np.zeros((shape, shape), np.uint8)\n",
    "    num_label = cluster_points.shape[0]\n",
    "    for i in range(num_label):\n",
    "        for point in cluster_points[i]:\n",
    "            pic[point[0], point[1]] = 50 + i * int((255 - 50) / num_label) \n",
    "    return pic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Curve line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_curve_lines(curve_clusters):\n",
    "    curve_list = []\n",
    "    if(len(curve_clusters)==0):\n",
    "        return curve_list\n",
    "    for cluster in curve_clusters:\n",
    "        curve = []\n",
    "        x_pre = cluster[0,0]\n",
    "        y_sum = 0\n",
    "        num = 0\n",
    "        for point in cluster:\n",
    "            point = np.array(point, dtype=np.uint16)\n",
    "            if point[0] == x_pre:\n",
    "                y_sum = y_sum + point[1]\n",
    "                num = num + 1\n",
    "            else:\n",
    "                y_mean = int(y_sum * 1. / num)\n",
    "                curve.append([x_pre, y_mean])\n",
    "                x_pre = point[0]\n",
    "                num = 1\n",
    "                y_sum = point[1]    \n",
    "                \n",
    "        curve.append([x_pre, int(y_sum * 1. / num)])\n",
    "        curve_list.append(curve)\n",
    "        \n",
    "    return curve_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Y line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 把一个聚类结果的二维数组根据X轴坐标转换成三维数组\n",
    "def get_x_pixels(cluster):\n",
    "    x_unique = np.unique(cluster[:,0])\n",
    "    x_pixels = [[] for i in range(len(x_unique))]\n",
    "    y_gap = [0 for i in range(len(x_unique))]\n",
    "    x_index = 0\n",
    "    for point in cluster:\n",
    "        if(point[0] == x_unique[x_index]):\n",
    "            x_pixels[x_index].append(point.tolist())\n",
    "        else:\n",
    "            x_index += 1\n",
    "            x_pixels[x_index].append(point.tolist())\n",
    "            \n",
    "    for i, x_pixel_line in enumerate(x_pixels):\n",
    "        if(len(x_pixel_line) == 0):\n",
    "            continue\n",
    "        for j in range(1, len(x_pixel_line)):\n",
    "            gap = abs(x_pixel_line[j][1] - x_pixel_line[j-1][1])\n",
    "            if(gap > y_gap[i]):\n",
    "                y_gap[i] = gap\n",
    "                \n",
    "    return x_pixels, y_gap\n",
    "\n",
    "#判断Y型线开口方向：向上返回True，向下返回False\n",
    "def judge_open(y_gap):\n",
    "    max_gap = max(y_gap)\n",
    "    max_index = y_gap.index(max_gap)\n",
    "    if(max_index == 0 or (max_gap - y_gap[max_index + 1]) > 3):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def find_meeting(x_pixels, y_gap, y_open):\n",
    "    meet_point = [0,0]\n",
    "    x_index = 0\n",
    "    for i, gap in enumerate(y_gap):\n",
    "        if gap > 1 and gap < 4:\n",
    "            meet_point[0] = x_pixels[i][0][0]\n",
    "            x_index = i\n",
    "            break\n",
    "    meet_point[1] = int(np.mean(np.array(x_pixels[x_index])[:,1]))\n",
    "    return meet_point\n",
    "    \n",
    "def fit_Y_lines(Y_clusters):\n",
    "    Y_lines = []\n",
    "    if(len(Y_clusters)==0):\n",
    "        return Y_lines\n",
    "    \n",
    "    for cluster in Y_clusters:\n",
    "        x_pixels, y_gap = get_x_pixels(cluster)\n",
    "#         print(x_pixels)\n",
    "        y_open = judge_open(y_gap)\n",
    "        meet_point = find_meeting(x_pixels, y_gap, y_open)\n",
    "        print(y_open, meet_point)\n",
    "    \n",
    "    return Y_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_result_classifier(img):\n",
    "    CLASS_WEIGHT = [1, 9, 6, 5]\n",
    "    json_string = open('/home/mc16/zhy/Classification_Model/model_json.json').read()\n",
    "    model_1 = model_from_json(json_string)\n",
    "    model_1 = model_1.load_weights('/home/mc16/zhy/Classification_Model/classifier-final-weight_2.h5')\n",
    "    classification_result = model_1.predict(x=img)\n",
    "    return classification_result.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def line2img(line, shape):\n",
    "    x_list = line[:, 0]\n",
    "    y_list = line[:, 1]\n",
    "    x_range = x_list.max() - x_list.min() + 1\n",
    "    y_range = y_list.max() - y_list.min() + 1\n",
    "    x_list = x_list - x_list.min()\n",
    "    y_list = y_list - y_list.min()\n",
    "    pic = np.zeros((x_range, y_range), np.uint8)\n",
    "    for x, y in zip(x_list, y_list):\n",
    "        pic[x, y] = 255\n",
    "    img = cv2.resize(pic ,(shape, shape))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cluster_result_classifier_helper(cluster):\n",
    "    result = []\n",
    "    # print cluster.shape[0]\n",
    "    for i in range(cluster.shape[0]):\n",
    "        img = line2img(cluster[i], 32)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        img = img.reshape(1, 32, 32, 1)\n",
    "        classification_result = cluster_result_classifier(img)\n",
    "        print classification_result\n",
    "        result.append(classification_result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_image = \"/home/mc16/result/val_cluster_06-18-05:50:42.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 30, 30, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 12, 12, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10, 10, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                51264     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 68,084\n",
      "Trainable params: 67,988\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-3a2b3e6fa76e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCLUSTER_EPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMIN_SAMPLES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCLUSTER_MINN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRANGE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCLUSTER_RANGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mclassifier_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_result_classifier_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mclassifier_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-df1dcf0f7ab1>\u001b[0m in \u001b[0;36mcluster_result_classifier_helper\u001b[0;34m(cluster)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mclassification_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_result_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mclassification_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-c6997ac69ed8>\u001b[0m in \u001b[0;36mcluster_result_classifier\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/mc16/zhy/Classification_Model/classifier-final-weight_2.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mclassification_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclassification_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "CUT_TOP_THRESH = 5\n",
    "CLUSTER_EPS = 1.9\n",
    "CLUSTER_MINN = 50\n",
    "CLUSTER_RANGE = 27\n",
    "FIT_THETA = 20\n",
    "FIT_RO = 20\n",
    "\n",
    "index = random.randint(0, len(val_image))\n",
    "img = val_images[index]\n",
    "seg = detect_points(img, model, DATA_SHAPE)\n",
    "cut, top_index = cut_top(seg, CUT_TOP_THRESH, frac=0.12)\n",
    "point = matrix_to_point(cut)\n",
    "\n",
    "cluster = get_clusters(point, EPS = CLUSTER_EPS, MIN_SAMPLES = 3, minN = CLUSTER_MINN, RANGE = CLUSTER_RANGE)\n",
    "classifier_result = cluster_result_classifier_helper(cluster)\n",
    "print classifier_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show(CUT_TOP_THRESH=10, CLUSTER_EPS=1.9, CLUSTER_MINN=50, CLUSTER_RANGE=20, FIT_THETA=15, FIT_RO=35, index=-1):\n",
    "    if index == -1:\n",
    "        index = random.randint(0, len(val_images))\n",
    "    img = val_images[index]\n",
    "    label = val_labels[index,:,:,1]\n",
    "    seg = detect_points(img, model, DATA_SHAPE)\n",
    "    cut, top_index = cut_top(seg, CUT_TOP_THRESH, frac=0.12)\n",
    "    point = matrix_to_point(cut)\n",
    "    \n",
    "    cluster = get_clusters(point, EPS = CLUSTER_EPS, MIN_SAMPLES = 3, minN = CLUSTER_MINN, RANGE = CLUSTER_RANGE)\n",
    "    classifier_result = cluster_result_classifier_helper(cluster)\n",
    "    print classifier_result\n",
    "    \n",
    "    cluster_img = cluster_to_img(cluster, DATA_SHAPE)\n",
    "    straight_lines = fit_straight_lines(cluster, top_index, ANGEL=FIT_THETA, DIS=FIT_RO)\n",
    "    curve_lines = fit_curve_lines(cluster)\n",
    "    Y_lines = fit_Y_lines(cluster)\n",
    "    straight_img = lines_to_img(straight_lines, DATA_SHAPE)\n",
    "    curve_img = lines_to_img(curve_lines, DATA_SHAPE)\n",
    "    print(len(curve_lines[0]), curve_lines[0])\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 4, figsize=(20,5))\n",
    "    axs[0].set_title('label', fontsize=18), axs[0].imshow(label, cmap='gray')\n",
    "    axs[1].set_title('cluster', fontsize=18), axs[1].imshow(cluster_img, cmap='gray')\n",
    "    axs[2].set_title('straight', fontsize=18), axs[2].imshow(straight_img,cmap='gray')\n",
    "    axs[3].set_title('curve', fontsize=18), axs[3].imshow(curve_img,cmap='gray')\n",
    "    print(\"index %s\"%index, \"cluster number %s\"%len(cluster), \"fit number %s\"%len(straight_lines), \"top index %s\"%top_index)\n",
    "    plt.show()\n",
    "    \n",
    "CUT_TOP_THRESH = 5\n",
    "CLUSTER_EPS = 1.9\n",
    "CLUSTER_MINN = 50\n",
    "CLUSTER_RANGE = 27\n",
    "FIT_THETA = 20\n",
    "FIT_RO = 20\n",
    "# show(CUT_TOP_THRESH, CLUSTER_EPS, CLUSTER_MINN, CLUSTER_RANGE, FIT_THETA, FIT_RO, 741)\n",
    "show(CUT_TOP_THRESH, CLUSTER_EPS, CLUSTER_MINN, CLUSTER_RANGE, FIT_THETA, FIT_RO, -1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
